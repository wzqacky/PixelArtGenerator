import os
import cv2
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from PIL import Image
from sklearn.cluster import KMeans
from scipy.ndimage import convolve
import torch
from transformers import AutoModelForImageClassification, AutoImageProcessor

# ===================== Configuration Parameters =====================
class Config:
    # Image path configuration (modify according to your actual setup)
    BASELINE_FOLDER = "./base_model_images"  # Images generated by Stable Diffusion Baseline
    FINETUNED_FOLDER = "./full_finetuned_images"  # Images generated by your finetuned model
    OUTPUT_CSV = "./evaluation_results.csv"  # Path to save evaluation results
    OUTPUT_PLOT = "./comparison_plot.png"  # Path to save visualization chart
    
    # Model configuration
    AESTHETIC_MODEL_NAME = "laion/CLIP-ViT-B-32-laion2B-s34B-b79K"  # Aesthetic evaluation model
    DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
    
    # Pixelation evaluation parameters
    COLOR_QUANTIZE_N_CLUSTERS = 16  # Common color count for pixel art (for color quantization scoring)
    PIXEL_BLOCK_THRESHOLD = 0.3  # Threshold for pixel block detection

# ===================== Utility Functions =====================
def load_image(image_path: str) -> Image.Image:
    """Load image and convert to RGB format"""
    try:
        img = Image.open(image_path).convert("RGB")
        return img
    except Exception as e:
        print(f"Warning: Failed to load image {image_path}, error: {e}")
        return None

def calculate_color_quantization_score(img: Image.Image) -> float:
    """Calculate color quantization score (pixel art characteristic: few and concentrated colors)
    Score range: 0-1 (higher = more pixelated)
    """
    # Convert to numpy array and reshape to pixels
    img_np = np.array(img)
    h, w, _ = img_np.shape
    pixels = img_np.reshape(-1, 3)
    
    # K-Means clustering for color quantization
    kmeans = KMeans(n_clusters=Config.COLOR_QUANTIZE_N_CLUSTERS, random_state=42)
    kmeans.fit(pixels)
    cluster_counts = np.bincount(kmeans.labels_)
    
    # Calculate color distribution concentration (ratio of top 5 colors)
    top5_ratio = cluster_counts.argsort()[-5:].sum() / len(pixels)
    
    # Calculate original color count (normalized to 0-1)
    unique_colors = len(np.unique(pixels, axis=0))
    color_density = 1 - (unique_colors / (h * w))  # Pixel art has fewer colors, lower density = higher score
    
    # Comprehensive score (weights can be adjusted)
    score = (top5_ratio * 0.6) + (color_density * 0.4)
    return min(max(score, 0.0), 1.0)  # Clip to 0-1 range

def calculate_pixel_block_score(img: Image.Image) -> float:
    """Calculate pixel block integrity score (detect grid-like edges)
    Score range: 0-1 (higher = clearer pixel blocks)
    """
    img_np = np.array(img)
    gray = cv2.cvtColor(img_np, cv2.COLOR_RGB2GRAY)
    
    # Edge detection (Sobel operator)
    sobel_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)
    sobel_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
    edge_magnitude = np.sqrt(sobel_x**2 + sobel_y**2)
    edge_magnitude = (edge_magnitude / edge_magnitude.max()) if edge_magnitude.max() > 0 else edge_magnitude
    
    # Detect periodicity of horizontal and vertical edges (pixel art grid feature)
    kernel_h = np.array([[1, 1, 1], [0, 0, 0], [-1, -1, -1]])
    kernel_v = np.array([[1, 0, -1], [1, 0, -1], [1, 0, -1]])
    
    h_edge = convolve(edge_magnitude, kernel_h)
    v_edge = convolve(edge_magnitude, kernel_v)
    
    # Calculate edge consistency (higher = more grid-like)
    h_consistency = np.mean((h_edge > Config.PIXEL_BLOCK_THRESHOLD).astype(float))
    v_consistency = np.mean((v_edge > Config.PIXEL_BLOCK_THRESHOLD).astype(float))
    
    return (h_consistency + v_consistency) / 2.0

def calculate_pixelization_score(img: Image.Image) -> float:
    """Comprehensive pixelation score (color quantization + pixel block integrity)"""
    color_score = calculate_color_quantization_score(img)
    block_score = calculate_pixel_block_score(img)
    return (color_score * 0.7) + (block_score * 0.3)  # Weights can be adjusted

def load_aesthetic_model() -> tuple[AutoImageProcessor, AutoModelForImageClassification]:
    """Load pre-trained aesthetic evaluation model"""
    processor = AutoImageProcessor.from_pretrained(Config.AESTHETIC_MODEL_NAME)
    model = AutoModelForImageClassification.from_pretrained(Config.AESTHETIC_MODEL_NAME)
    model.to(Config.DEVICE)
    model.eval()
    return processor, model

def calculate_aesthetic_score(img: Image.Image, processor, model) -> float:
    """Calculate aesthetic quality score (0-10 points, higher = more aesthetically pleasing)"""
    inputs = processor(images=img, return_tensors="pt").to(Config.DEVICE)
    with torch.no_grad():
        outputs = model(**inputs)
        logits = outputs.logits
        score = torch.sigmoid(logits).item() * 10  # Convert to 0-10 scale
    return score

# ===================== Batch Evaluation Main Function =====================
def batch_evaluate() -> pd.DataFrame:
    """Batch evaluate images from two models"""
    # Load aesthetic model
    print(f"Loading aesthetic evaluation model to {Config.DEVICE}...")
    aesthetic_processor, aesthetic_model = load_aesthetic_model()
    
    # Collect all image paths
    results = []
    model_folders = [
        ("baseline", Config.BASELINE_FOLDER),
        ("finetuned", Config.FINETUNED_FOLDER)
    ]
    
    for model_type, folder_path in model_folders:
        print(f"\nEvaluating {model_type} model images (path: {folder_path})...")
        if not os.path.exists(folder_path):
            print(f"Warning: Folder {folder_path} does not exist, skipping this model!")
            continue
        
        # Traverse all images in the folder (supports common formats)
        image_extensions = (".png", ".jpg", ".jpeg", ".bmp")
        image_paths = [
            os.path.join(folder_path, f)
            for f in os.listdir(folder_path)
            if f.lower().endswith(image_extensions)
        ]
        
        if len(image_paths) == 0:
            print(f"Warning: No images found in folder {folder_path}, skipping this model!")
            continue
        
        # Batch process images
        for idx, img_path in enumerate(image_paths, 1):
            img = load_image(img_path)
            if img is None:
                continue
            
            # Calculate scores
            pixelization_score = calculate_pixelization_score(img)
            aesthetic_score = calculate_aesthetic_score(img, aesthetic_processor, aesthetic_model)
            
            # Save results
            results.append({
                "image_path": img_path,
                "model_type": model_type,
                "pixelization_score": round(pixelization_score, 4),  # 0-1 scale
                "aesthetic_score": round(aesthetic_score, 4)  # 0-10 scale
            })
            
            if idx % 10 == 0:
                print(f"Processed {idx}/{len(image_paths)} images")
    
    # Convert to DataFrame and save
    df = pd.DataFrame(results)
    df.to_csv(Config.OUTPUT_CSV, index=False, encoding="utf-8")
    print(f"\nEvaluation results saved to {Config.OUTPUT_CSV}")
    return df

# ===================== Result Visualization & Comparison =====================
def visualize_comparison(df: pd.DataFrame):
    """Generate comparison visualization chart"""
    plt.figure(figsize=(12, 5))
    
    # Calculate statistical metrics
    stats = df.groupby("model_type").agg({
        "pixelization_score": ["mean", "std"],
        "aesthetic_score": ["mean", "std"]
    }).round(4)
    
    print("\n=== Evaluation Results Statistics ===")
    print(stats)
    
    # Subplot 1: Pixelization score comparison (box plot)
    plt.subplot(1, 2, 1)
    box_data = [
        df[df["model_type"] == "baseline"]["pixelization_score"],
        df[df["model_type"] == "finetuned"]["pixelization_score"]
    ]
    plt.boxplot(box_data, labels=["Baseline", "Finetuned"])
    plt.title("Pixelation Score Comparison (Higher = More Pixelated)")
    plt.ylabel("Score (0-1)")
    plt.ylim(0, 1)
    
    # Subplot 2: Aesthetic score comparison (box plot)
    plt.subplot(1, 2, 2)
    box_data = [
        df[df["model_type"] == "baseline"]["aesthetic_score"],
        df[df["model_type"] == "finetuned"]["aesthetic_score"]
    ]
    plt.boxplot(box_data, labels=["Baseline", "Finetuned"])
    plt.title("Aesthetic Quality Comparison (Higher = More Pleasing)")
    plt.ylabel("Score (0-10)")
    plt.ylim(0, 10)
    
    plt.tight_layout()
    plt.savefig(Config.OUTPUT_PLOT, dpi=300, bbox_inches="tight")
    print(f"\nComparison chart saved to {Config.OUTPUT_PLOT}")
    plt.show()

# ===================== Main Program Entry =====================
if __name__ == "__main__":
    # 1. Batch evaluation
    evaluation_df = batch_evaluate()
    
    # 2. Result visualization
    if not evaluation_df.empty:
        visualize_comparison(evaluation_df)
    else:
        print("No valid evaluation results, cannot generate comparison chart!")